version: "3.9"

services:
  # ===================================
  # Primary Backend (Auth)
  # ===================================
  primary-backend:
    image: primary-backend:latest
    container_name: primary-backend
    depends_on:
      - kafka
    environment:
      JWT_SECRET: "thiismykey"
      JWT_EXPIRES_IN: "24h"
      PORT: 3000
      DATABASE_URL: "postgresql://?sslmode=require&channel_binding=require"
      NODE_ENV: dev
    ports:
      - "3000:3000"
    restart: always
    networks:
      - backend_network

  # ===================================
  # Workflow Service
  # ===================================
  work_flow:
    image: work_flow:latest
    container_name: work_flow
    depends_on:
      - kafka
    environment:
      PORT: 3004
      DATABASE_URL: "postgresql://?sslmode=require&channel_binding=require"
      NODE_ENV: dev
      WEB_HOOK_URL: "http://localhost:3004/api/hooks"
    ports:
      - "3004:3004"
    restart: always
    networks:
      - backend_network

  # ===================================
  # Worker
  # ===================================
  worker:
    image: worker:latest
    container_name: worker
    depends_on:
      - kafka
    environment:
      KAFKA_BROKER: kafka:9092
      APP_ENV: production
      AWS_BUCKET_NAME: "your-s3-bucket"
      AWS_REGION: "your-region"
      AWS_ACCESS_KEY_ID: "your-access-key"
      AWS_SECRET_ACCESS_KEY: "your-secret-key"
      KAFKA_CLIENT_ID: "myKafka"
      KAFKA_BROKERS_NAME: kafka:9092
      KAFKA_TOPIC: "KAFKA_TOPIC"
      NODE_ENV: dev
      DATABASE_URL: "postgresql://?sslmode=require&channel_binding=require"
    restart: always
    networks:
      - backend_network

  # ===================================
  # Processor
  # ===================================
  processor:
    image: processor:latest
    container_name: processor
    depends_on:
      - kafka
    environment:
      KAFKA_BROKER: kafka:9092
      APP_ENV: production
      KAFKA_TOPIC: "KAFKA_TOPIC"
      KAFKA_BROKERS_NAME: kafka:9092
      KAFKA_CLIENT_ID: "KAFKA_CLIENT_ID"
      NODE_ENV: dev
      DATABASE_URL: "postgresql://?sslmode=require&channel_binding=require"
    restart: always
    networks:
      - backend_network

  # ===================================
  # Cron Job
  # ===================================
  cron_job:
    image: cron_job:latest
    container_name: cron_job
    depends_on:
      - kafka
    environment:
      KAFKA_BROKERS_NAME: kafka:9092
      KAFKA_CLIENT_ID: "KAFKA_CLIENT_ID"
      KAFKA_TOPIC: "KAFKA_TOPIC"
      NODE_ENV: dev
      DATABASE_URL: "postgresql://?sslmode=require&channel_binding=require"
    restart: always
    networks:
      - backend_network

  # ===================================
  # Auto Worker
  # ===================================
  auto_worker:
    image: auto_worker:latest
    container_name: auto_worker
    depends_on:
      - kafka
    environment:
      NODE_ENV: dev
      DATABASE_URL: "postgresql://?sslmode=require&channel_binding=require"
      GROUP_ID: "KAFKA_GROUP_ID"
      TOPIC_NAME: "KAFKA_TOPIC_NAME"
      KAFKA_CLIENT_ID: "KAFKA_CLIENT_ID"
      KAFKA_BROKERS_NAME: kafka:9092
      APP_ENV: dev
      KAFKA_TOPIC: "KAFKA_TOPIC"
      AWS_BUCKET_NAME: "your-s3-bucket"
      AWS_REGION: "your-region"
      AWS_ACCESS_KEY_ID: "your-access-key"
      AWS_SECRET_ACCESS_KEY: "your-secret-key"
    restart: always
    networks:
      - backend_network

  # ===================================
  # Apache Kafka (Optimized for 2GB RAM)
  # ===================================
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      # ----- Core KRaft configuration -----
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_LOG_DIRS: /var/lib/kafka/data

      # ----- Memory limit -----
      KAFKA_HEAP_OPTS: "-Xmx1536M -Xms512M"

      # ----- Lightweight tuning -----
      KAFKA_NUM_NETWORK_THREADS: 3
      KAFKA_NUM_IO_THREADS: 3
      KAFKA_NUM_REPLICA_FETCHERS: 1
      KAFKA_QUEUED_MAX_REQUESTS: 20

      # ----- Single-node cluster -----
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      # ----- Logging & cleanup -----
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 10000
      KAFKA_LOG_FLUSH_INTERVAL_MS: 3000
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_CLEANER_ENABLE: "true"

      # ----- Cluster ID -----
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

    volumes:
      - kafka-data:/var/lib/kafka/data
    restart: unless-stopped
    networks:
      - backend_network
    deploy:
      resources:
        limits:
          memory: 2g

  # ===================================
  # Nginx Reverse Proxy
  # ===================================
  nginx:
    image: nginx:latest
    container_name: nginx-proxy
    depends_on:
      - primary-backend
      - work_flow
    ports:
      - "80:80"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d
    restart: always
    networks:
      - backend_network

# ===================================
# Networking & Volumes
# ===================================
networks:
  backend_network:
    driver: bridge

volumes:
  kafka-data:
